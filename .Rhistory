legend.title = element_blank(),
legend.key.width = unit(2, "line"),
legend.spacing.x = unit(0.3, 'cm'))
ggplot(subset(all.res, reg == regions_subset[2017]), aes(x = maf.pop, y = delta, color = factor(denclue.clust.outlier), shape = factor(truth))) +
geom_point(size = 4, alpha = 0.75) +
#geom_point(aes(x = points_final_2, y = points_final_1), color = "black", size = 3, alpha = 0.5) +
geom_point(aes(x = denclue_center_2, y = denclue_center_1), color = "black", size = 2, alpha = 0.5) +
theme_minimal(base_size = 18) +
ylab("Delta") +
xlab("log10(MAF)") +
ggtitle("Example Region") +
#scale_color_manual(values = unpaired_cols[1:4]) +
theme(legend.position = "top",
legend.title = element_blank(),
legend.key.width = unit(2, "line"),
legend.spacing.x = unit(0.3, 'cm'))
head(all.res)
ggplot(subset(all.res, reg == regions_subset[2017]), aes(x = maf.pop, y = delta, color = factor(denclue_clust), shape = factor(truth))) +
geom_point(size = 4, alpha = 0.75) +
#geom_point(aes(x = points_final_2, y = points_final_1), color = "black", size = 3, alpha = 0.5) +
geom_point(aes(x = denclue_center_2, y = denclue_center_1), color = "black", size = 2, alpha = 0.5) +
theme_minimal(base_size = 18) +
ylab("Delta") +
xlab("log10(MAF)") +
ggtitle("Example Region") +
#scale_color_manual(values = unpaired_cols[1:4]) +
theme(legend.position = "top",
legend.title = element_blank(),
legend.key.width = unit(2, "line"),
legend.spacing.x = unit(0.3, 'cm'))
ggplot(subset(all.res, reg == regions_subset[4017]), aes(x = maf.pop, y = delta, color = factor(denclue_clust), shape = factor(truth))) +
geom_point(size = 4, alpha = 0.75) +
#geom_point(aes(x = points_final_2, y = points_final_1), color = "black", size = 3, alpha = 0.5) +
geom_point(aes(x = denclue_center_2, y = denclue_center_1), color = "black", size = 2, alpha = 0.5) +
theme_minimal(base_size = 18) +
ylab("Delta") +
xlab("log10(MAF)") +
ggtitle("Example Region") +
#scale_color_manual(values = unpaired_cols[1:4]) +
theme(legend.position = "top",
legend.title = element_blank(),
legend.key.width = unit(2, "line"),
legend.spacing.x = unit(0.3, 'cm'))
######################################################################################################
#     simulate_distribution_diffParams.R
#     Date created March 1, 2019
#
#     This script is to summarize diagnostic measures from 100 simulations
#
#     Last updated - March 1, 2019
######################################################################################################
options(stringsAsFactors = F)
# library loads
library(ggplot2)
library(dplyr)
library(tidyr)
library(RColorBrewer)
library(grid)
library(gridExtra)
library(xtable)
# Set up working directory
# PROJECT PATH
proj_path <- "../phd_work/localization/"
# HOME
#compbio <-"/Users/rachelblumhagen/Projects/NJ/"
# WORK
compbio <-"/Users/blumhagenr/Projects/NJ/"
#
# # Set working directory
compbio_path <- paste(compbio, proj_path, sep = "")
setwd(compbio_path)
# # Load functions
source(file = "simulating_data/R/simulateRare.R")
source(file = "R/runSKATO.R")
source(file = "R/forwardSelection.R")
source(file = "R/forwardSelectionConstantRho.R")
source(file = "R/evaluateCutoff.R")
source(file = "R/parametricVariance.R")
source(file = "R/nonparametricVariance.R")
source(file = "R/nonparametricVariance_MAD.R")
################# ******************* EXPLORE ONE DIMENSION
## Format HAPS and POS file
haps <- read.table(file = "simulating_data/cosi/bestfit/out.hap-1")
pos <- read.table(file = "simulating_data/cosi/bestfit/out.pos-1", header = TRUE)
208+40-25
haps <- haps[,-c(1:2)]
haps <- apply(haps, 2, function(x){ifelse(x == 2, 0, x)})
## Format SNP name
#pos$SNP_name = paste0("SNP.", pos$SNP)
pos$SNP_name = paste0("C", pos$CHROM, ".", pos$CHROM_POS)
colnames(haps) <- pos$SNP_name
num.regions <- 50
num.sims <- 1000
### Remove first two columns and convert to 1 for derived and 0 for ancestral
haps <- haps[,-c(1:2)]
haps <- apply(haps, 2, function(x){ifelse(x == 2, 0, x)})
## Format SNP name
#pos$SNP_name = paste0("SNP.", pos$SNP)
pos$SNP_name = paste0("C", pos$CHROM, ".", pos$CHROM_POS)
colnames(haps) <- pos$SNP_name
######################################################################################################
#     simulate_distribution_diffParams.R
#     Date created March 1, 2019
#
#     This script is to summarize diagnostic measures from 100 simulations
#
#     Last updated - March 1, 2019
######################################################################################################
options(stringsAsFactors = F)
# library loads
library(ggplot2)
library(dplyr)
library(tidyr)
library(RColorBrewer)
library(grid)
library(gridExtra)
library(xtable)
# Set up working directory
# PROJECT PATH
proj_path <- "../phd_work/localization/"
# HOME
#compbio <-"/Users/rachelblumhagen/Projects/NJ/"
# WORK
compbio <-"/Users/blumhagenr/Projects/NJ/"
#
# # Set working directory
compbio_path <- paste(compbio, proj_path, sep = "")
setwd(compbio_path)
# # Load functions
source(file = "simulating_data/R/simulateRare.R")
source(file = "R/runSKATO.R")
source(file = "R/forwardSelection.R")
source(file = "R/forwardSelectionConstantRho.R")
source(file = "R/evaluateCutoff.R")
source(file = "R/parametricVariance.R")
source(file = "R/nonparametricVariance.R")
source(file = "R/nonparametricVariance_MAD.R")
################# ******************* EXPLORE ONE DIMENSION
## Format HAPS and POS file
haps <- read.table(file = "simulating_data/cosi/bestfit/out.hap-1")
pos <- read.table(file = "simulating_data/cosi/bestfit/out.pos-1", header = TRUE)
### Remove first two columns and convert to 1 for derived and 0 for ancestral
haps <- haps[,-c(1:2)]
haps <- apply(haps, 2, function(x){ifelse(x == 2, 0, x)})
## Format SNP name
#pos$SNP_name = paste0("SNP.", pos$SNP)
pos$SNP_name = paste0("C", pos$CHROM, ".", pos$CHROM_POS)
colnames(haps) <- pos$SNP_name
sim.region.params <- NULL
sim.regions.results <- NULL
params <- expand.grid(prop.assoc.variant = c(0.10, 0.20), cc = c(0.4, 0.8))
params$idx <- c(1:dim(params)[1])
skato.cutoff <- 0.05
params
sim.region.params <- NULL
sim.regions.results <- NULL
ptm <- proc.time()
for (par.idx in c(1:length(params$idx))){
## reset the seed to sample the same 50 regions
set.seed(1)
for (region in 1:50){
## This simulation approach treats the population as the source of the maf and definition of rare
# set.seed(20180919)
haps.region <- sampleRareGeneFromHaplotypes(haps, pos, maf.cutoff = 0.03, size.kb = 3)
## Set up parameters
prevalence = 0.05
aa = log(prevalence/(1-prevalence))
prop.assoc.variant = params$prop.assoc.variant[par.idx]
cc = params$cc[par.idx]
cs.no = 1000
cn.no = 1000
## SKATO parameters
# skato.cutoff = 0.05
## Use above parameters to set up associated variants
num.assoc.variant = round(dim(haps.region)[2]*prop.assoc.variant)
MAF = colMeans(haps.region)
select.SNP <- sample(colnames(haps.region), num.assoc.variant, replace = F)
beta_k <- cc*abs(log10(MAF[select.SNP]))
## save region information
region.params <- data.frame(idx = par.idx,
region = region,
SNP = names(MAF),
MAF = MAF,
select.SNP = (names(MAF) %in% select.SNP),
odds.ratio = exp(beta_k)[match(names(MAF), select.SNP)])
sim.region.params <- rbind(sim.region.params, region.params)
## Set up simulation matrix
#ptm <- proc.time()
sim.results <- NULL
for (i in 1:1000){
## Sample genotypes
sim.genotype <- genotype(population = haps.region, sample.size = 40000)
## Generate phenotypes
sim.phenotype <- phenotype(genotype.data = sim.genotype, asso.variant.id = select.SNP, odds.ratio = exp(beta_k), intercept = aa, sample.size = dim(sim.genotype)[1])
## Make equal # cases and controls
cn <- which(sim.phenotype$disease.status == 0)
cs <- which(sim.phenotype$disease.status == 1)
#set.seed(seed1)
cn.id <- sample(cn, cn.no, replace = FALSE)
#set.seed(seed2)
cs.id <- sample(cs, cs.no, replace = FALSE)
disease.status <- sim.phenotype$disease.status[c(cn.id, cs.id)]
#genotype.data <- as.matrix(sim.region[c(cn.id, cs.id),])
raw_dat <- data.frame(cbind(PHENOTYPE = (sim.phenotype$disease.status[c(cn.id, cs.id)] + 1),
sim.genotype[c(cn.id, cs.id),]))
# Subset data to only those variants observed
observed <- which(colSums(raw_dat) != 0)
raw_dat <- raw_dat[,observed]
# Determine if SKAT-O is significant (use adjusted p-value)
res.org <- runSKATO(raw_dat)
# If SKAT-O signficant, run forwardSelection
if (res.org$p.value < params$skato.cutoff[par.idx]){
## Run leave-one-out SKATO
res <- forwardSelectionConstantRho(raw_dat)
## Make diagnostic plots
# res <- diagnosticPlots(res)
## Determine truth from select.SNP above
res$ind.stats$truth <- ifelse(res$ind.stats$SNP_excluded %in% select.SNP, TRUE, FALSE)
res$ind.stats$odds.ratio <- exp(beta_k)[match(res$ind.stats$SNP_excluded, select.SNP)]
res$ind.stats$maf.pop <- MAF[res$ind.stats$SNP_excluded]
res$ind.stats$maf.control <- c(NA, apply(raw_dat[,-1], 2, function(x){mean(x[raw_dat$PHENOTYPE == 1])}))
res$ind.stats$maf.case <- c(NA, apply(raw_dat[,-1], 2, function(x){mean(x[raw_dat$PHENOTYPE == 2])}))
## Calculate Tukey Fences to call outliers
res <- calculateTukeyFences(res)
# res <- evaluateCutoff(res, test = "tukey.mild")
# res <- evaluateCutoff(res, test = "tukey.extreme")
## Calculate MAD
res <- calculateMAD(res, cutoff = 3)
#res <- evaluateCutoff(res, test = "mad.outlier")
## Calculate parametric SD
res <- calculateSD(res, cutoff = 3)
#res <- evaluateCutoff(res, test = "sd.outlier")
## Save results for given sample measures (sensitivity, specificity, PPV, NPV)
# sim.sub <- rbind(data.frame(cutoff = "tukey.mild", res$tukey.mild),
#                  data.frame(cutoff = "tukey.extreme", res$tukey.extreme),
#                  data.frame(cutoff = "mad.outlier", res$mad.outlier),
#                  data.frame(cutoff = "sd.outlier", res$sd.outlier))
## Explore decision and delta of associated variants
#sim.sub <- subset(res$ind.stats, truth == TRUE)
## Explore decision and delta of all variants
sim.sub <- res$ind.stats
## Save other information
sim.sub$skato.pvalue = res.org$p.value
sim.sub$iteration = i
sim.sub$number.vars = length(res$ind.stats$truth[-1])
sim.sub$number.assoc = sum(res$ind.stats$truth[-1])
sim.sub$param.idx = par.idx
sim.sub$region = region
sim.sub$region.num.variant = dim(haps.region)[2]
sim.sub$region.num.assoc.variant = num.assoc.variant
## Append to results
sim.results <- rbind(sim.results, sim.sub)
}
}
## Append to region level results
sim.regions.results <- rbind(sim.regions.results, sim.results)
}
}
## print the time
proc.time() - ptm
## set up parameter grid
params <- expand.grid(prop.assoc.variant = c(0.10, 0.20), cc = c(0.4, 0.8))
params$idx <- c(1:dim(params)[1])
skato.cutoff <- 0.05
sim.region.params <- NULL
sim.regions.results <- NULL
ptm <- proc.time()
for (par.idx in c(1:length(params$idx))){
## reset the seed to sample the same 50 regions
set.seed(1)
for (region in 1:50){
## This simulation approach treats the population as the source of the maf and definition of rare
# set.seed(20180919)
haps.region <- sampleRareGeneFromHaplotypes(haps, pos, maf.cutoff = 0.03, size.kb = 3)
## Set up parameters
prevalence = 0.05
aa = log(prevalence/(1-prevalence))
prop.assoc.variant = params$prop.assoc.variant[par.idx]
cc = params$cc[par.idx]
cs.no = 1000
cn.no = 1000
## SKATO parameters
# skato.cutoff = 0.05
## Use above parameters to set up associated variants
num.assoc.variant = round(dim(haps.region)[2]*prop.assoc.variant)
MAF = colMeans(haps.region)
select.SNP <- sample(colnames(haps.region), num.assoc.variant, replace = F)
beta_k <- cc*abs(log10(MAF[select.SNP]))
## save region information
region.params <- data.frame(idx = par.idx,
region = region,
SNP = names(MAF),
MAF = MAF,
select.SNP = (names(MAF) %in% select.SNP),
odds.ratio = exp(beta_k)[match(names(MAF), select.SNP)])
sim.region.params <- rbind(sim.region.params, region.params)
## Set up simulation matrix
#ptm <- proc.time()
sim.results <- NULL
for (i in 1:1000){
## Sample genotypes
sim.genotype <- genotype(population = haps.region, sample.size = 40000)
## Generate phenotypes
sim.phenotype <- phenotype(genotype.data = sim.genotype, asso.variant.id = select.SNP, odds.ratio = exp(beta_k), intercept = aa, sample.size = dim(sim.genotype)[1])
## Make equal # cases and controls
cn <- which(sim.phenotype$disease.status == 0)
cs <- which(sim.phenotype$disease.status == 1)
#set.seed(seed1)
cn.id <- sample(cn, cn.no, replace = FALSE)
#set.seed(seed2)
cs.id <- sample(cs, cs.no, replace = FALSE)
disease.status <- sim.phenotype$disease.status[c(cn.id, cs.id)]
#genotype.data <- as.matrix(sim.region[c(cn.id, cs.id),])
raw_dat <- data.frame(cbind(PHENOTYPE = (sim.phenotype$disease.status[c(cn.id, cs.id)] + 1),
sim.genotype[c(cn.id, cs.id),]))
# Subset data to only those variants observed
observed <- which(colSums(raw_dat) != 0)
raw_dat <- raw_dat[,observed]
# Determine if SKAT-O is significant (use adjusted p-value)
res.org <- runSKATO(raw_dat)
# If SKAT-O signficant, run forwardSelection
if (res.org$p.value < skato.cutoff){
## Run leave-one-out SKATO
res <- forwardSelectionConstantRho(raw_dat)
## Make diagnostic plots
# res <- diagnosticPlots(res)
## Determine truth from select.SNP above
res$ind.stats$truth <- ifelse(res$ind.stats$SNP_excluded %in% select.SNP, TRUE, FALSE)
res$ind.stats$odds.ratio <- exp(beta_k)[match(res$ind.stats$SNP_excluded, select.SNP)]
res$ind.stats$maf.pop <- MAF[res$ind.stats$SNP_excluded]
res$ind.stats$maf.control <- c(NA, apply(raw_dat[,-1], 2, function(x){mean(x[raw_dat$PHENOTYPE == 1])}))
res$ind.stats$maf.case <- c(NA, apply(raw_dat[,-1], 2, function(x){mean(x[raw_dat$PHENOTYPE == 2])}))
## Calculate Tukey Fences to call outliers
res <- calculateTukeyFences(res)
# res <- evaluateCutoff(res, test = "tukey.mild")
# res <- evaluateCutoff(res, test = "tukey.extreme")
## Calculate MAD
res <- calculateMAD(res, cutoff = 3)
#res <- evaluateCutoff(res, test = "mad.outlier")
## Calculate parametric SD
res <- calculateSD(res, cutoff = 3)
#res <- evaluateCutoff(res, test = "sd.outlier")
## Save results for given sample measures (sensitivity, specificity, PPV, NPV)
# sim.sub <- rbind(data.frame(cutoff = "tukey.mild", res$tukey.mild),
#                  data.frame(cutoff = "tukey.extreme", res$tukey.extreme),
#                  data.frame(cutoff = "mad.outlier", res$mad.outlier),
#                  data.frame(cutoff = "sd.outlier", res$sd.outlier))
## Explore decision and delta of associated variants
#sim.sub <- subset(res$ind.stats, truth == TRUE)
## Explore decision and delta of all variants
sim.sub <- res$ind.stats
## Save other information
sim.sub$skato.pvalue = res.org$p.value
sim.sub$iteration = i
sim.sub$number.vars = length(res$ind.stats$truth[-1])
sim.sub$number.assoc = sum(res$ind.stats$truth[-1])
sim.sub$param.idx = par.idx
sim.sub$region = region
sim.sub$region.num.variant = dim(haps.region)[2]
sim.sub$region.num.assoc.variant = num.assoc.variant
## Append to results
sim.results <- rbind(sim.results, sim.sub)
}
}
## Append to region level results
sim.regions.results <- rbind(sim.regions.results, sim.results)
}
}
## print the time
proc.time() - ptm
150*2.50
head(sim.regions.results)
params
table(sim.regions.results$param.idx)
## merge parameter information
sim.regions.results <- merge(x = sim.regions.results,
y = params,
by.x = "param.idx",
by.y = "idx")
head(sim.regions.results)
## Summarize power, etc.
sim.regions.results %>%
group_by(param.idx, region) %>%
summarize(number.vars = mean(number.vars),
prop.assoc = mean(number.assoc/number.vars),
power = max(iteration))
## Summarize power, etc.
sim.means = sim.regions.results %>%
group_by(param.idx, region) %>%
summarize(number.vars = mean(number.vars),
prop.assoc = mean(number.assoc/number.vars),
power = max(iteration))
View(sim.means)
## Summarize power, etc.
sim.means = sim.regions.results %>%
group_by(param.idx, region) %>%
summarize(number.vars = mean(number.vars),
prop.assoc = mean(number.assoc/number.vars),
power = length(unique(iteration)))
View(sim.means)
library(qwraps2)
sim.means %>%
group_by(param.idx) %>%
summarize(number.vars = median_iqr(number.vars, digits = 2),
prop.assoc = median_iqr(prop.assoc, digits = 2),
power = median_iqr(power))
params
print(xtable(sim.means), file = "simulating_data/results/distributions/simulate_distribution_diffParams.html")
print(xtable(sim.means), type = "html", file = "simulating_data/results/distributions/simulate_distribution_diffParams.html")
sim.means = sim.means %>%
group_by(param.idx) %>%
summarize(number.vars = median_iqr(number.vars, digits = 2),
prop.assoc = median_iqr(prop.assoc, digits = 2),
power = median_iqr(power))
print(xtable(sim.means), type = "html", file = "simulating_data/results/distributions/simulate_distribution_diffParams.html")
sim.tmp <- subset(sim.regions.results, params.idx == 1)
sim.tmp <- subset(sim.regions.results, param.idx == 1)
length(unique(sim.tmp$SNP_excluded[sim.tmp$truth == TRUE]))
load("simulating_data/results/evaluating_cutoffs/1000cscn.50regions.1000samples.10perAssoc.ss1.RDa")
length(unique(sim.regions.results$SNP_excluded[sim.tmp$truth == TRUE]))
region_information = sim.regions.results %>%
group_by(region, iteration) %>%
summarize(number.vars = mean(number.vars), number.assoc = mean(number.assoc), region.num.variant = mean(region.num.variant), region.num.assoc.variant = mean(region.num.assoc.variant))
region_information$prop.assoc <- region_information$number.assoc/region_information$number.vars
region_information
# ###********************* Summarize characteristics of the 50 regions
#
# ## Look at power of SKAT-O by
region_iterations <- region_information %>% group_by(region) %>% summarize(its = n(),
region.num.variant = mean(region.num.variant),
region.num.assoc.variant = mean(region.num.assoc.variant),
prop.assoc.mean = mean(prop.assoc))
region_iterations
median_iqr(region_iterations$prop.assoc.mean)
# plot(region_iterations$prop.assoc.mean, region_iterations$its,
#      xlab = "Mean Proportion Associated", ylab = "# Iterations (SKAT-O < 0.05)/100",
#      main = paste0("Correlation = ", format(cor(region_iterations$prop.assoc.mean, region_iterations$its), digits = 4)), pch = 19)
#
# ## Plot of # iterations by total number variants
# plot(region_iterations$region.num.variant, region_iterations$its,
#      xlab = "Total Number Variants", ylab = "# Iterations (SKAT-O < 0.05)/100",
#      main = paste0("Correlation = ", format(cor(region_iterations$region.num.variant, region_iterations$its), digits = 4)), pch = 19)
#
# ## Numerical summaries
summary(region_iterations$prop.assoc.mean)
summary(region_iterations$its)
summary(region_iterations$region.num.variant)
## remove SNP_excluded
sim.regions.results <- subset(sim.regions.results, SNP_excluded != "NONE")
sim.means <- sim.regions.results %>%
group_by(region, SNP_excluded) %>%
summarize(obs = length(tukey.mild),
truth = mean(truth),
or = mean(odds.ratio),
maf.pop = mean(maf.pop),
delta = mean(delta),
tukey.mild = mean(tukey.mild),
tukey.extreme = mean(tukey.extreme),
mad.outlier = mean(mad.outlier),
sd.outlier = mean(sd.outlier))
table(sim.means$truth)
table(sim.means$truth[sim.means$delta < 0])
sim.directory <- "../../not_synced/localization/simulated_data/1000cscn.50regions.1000samples.10perAssoc.0.4c/"
num.regions <- 50
num.sims <- 500
load("simulating_data/results/evaluating_cutoffs/1000cscn.50regions.1000samples.10perAssoc.ss1.RDa")
head(sim.regions.results_
head(sim.regions.results)
plot(subset(sim.regions.results, region == 1 & iteration == 12)$delta, subset(sim.regions.results, region == 1 & iteration == 12)$SNP_excluded)
e
## remove SNP_excluded
sim.regions.results <- subset(sim.regions.results, SNP_excluded != "NONE")
tmp <- subset(sim.regions.results, region == 1)
iter <- unique(tmp$iteration)
iter
plot(tmp[tmp$iteration == iter[1],]$delta, tmp[tmp$iteration == iter[1],]$truth)
plot(tmp[tmp$iteration == iter[2],]$delta, tmp[tmp$iteration == iter[2],]$truth)
plot(tmp[tmp$iteration == iter[3],]$delta, tmp[tmp$iteration == iter[3],]$truth)
plot(tmp[tmp$iteration == iter[4],]$delta, tmp[tmp$iteration == iter[4],]$truth)
plot(tmp[tmp$iteration == iter5],]$delta, tmp[tmp$iteration == iter[5],]$truth)
plot(tmp[tmp$iteration == iter[5],]$delta, tmp[tmp$iteration == iter[5],]$truth)
plot(tmp[tmp$iteration == iter[6],]$delta, tmp[tmp$iteration == iter[6],]$truth)
plot(tmp[tmp$iteration == iter[1],]$delta, tmp[tmp$iteration == iter[1],]$maf.combined,  col = tmp[tmp$iteration == iter[1],]$truth)
plot(tmp[tmp$iteration == iter[1],]$delta, tmp[tmp$iteration == iter[1],]$maf.combined,  col = as.factor(tmp[tmp$iteration == iter[1],]$truth))
plot(tmp[tmp$iteration == iter[5],]$delta, tmp[tmp$iteration == iter[5],]$maf.combined,  col = as.factor(tmp[tmp$iteration == iter[5],]$truth))
plot(tmp[tmp$iteration == iter[6],]$delta, tmp[tmp$iteration == iter[6],]$maf.combined,  col = as.factor(tmp[tmp$iteration == iter[6],]$truth))
plot(tmp[tmp$iteration == iter[7],]$delta, tmp[tmp$iteration == iter[7],]$maf.combined,  col = as.factor(tmp[tmp$iteration == iter[7],]$truth))
plot(tmp[tmp$iteration == iter[8],]$delta, tmp[tmp$iteration == iter[8],]$maf.combined,  col = as.factor(tmp[tmp$iteration == iter[8],]$truth))
plot(tmp[tmp$iteration == iter[9],]$delta, tmp[tmp$iteration == iter[9],]$maf.combined,  col = as.factor(tmp[tmp$iteration == iter[9],]$truth))
plot(tmp[tmp$iteration == iter[5],]$delta, tmp[tmp$iteration == iter[5],]$maf.combined,  col = as.factor(tmp[tmp$iteration == iter[5],]$truth))
iter[5]
### Read in example dataset (in PLINK format using --recodeA)
example_directory <- "/Users/blumhagenr/Projects/phd_work/localization/R/example_code/"
raw_dat <- read.table(file = paste0(example_directory, "example_data.txt"))
head(raw_dat)
colMeans(raw_dat)
colSums(raw_dat)
load("raresift_functions.R")
### Read in example dataset (in PLINK format using --recodeA)
raw_dat <- read.table(file = "example_data.txt")
setwd("/Users/blumhagenr/Projects/phd_work/localization/R/example_code/")
## Load functions
load("raresift_functions.R")
### Read in example dataset (in PLINK format using --recodeA)
raw_dat <- read.table(file = "example_data.txt")
## Load functions
source("raresift_functions.R")
setwd("/Users/blumhagenr/Projects/phd_work/localization/R/example_code/")
## Load functions
source("raresift_functions.R")
### Read in example dataset (in PLINK format using --recodeA)
raw_dat <- read.table(file = "example_data.txt")
